{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import gym\n",
    "import cv2\n",
    "import copy\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(4)\n",
      "Observation space: Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "# env = gym.make('SpaceInvadersDeterministic-v4')\n",
    "print('Action space:', env.action_space)\n",
    "print('Observation space:', env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FRAMES = 4\n",
    "\n",
    "def filter_obs(obs, resize_shape=(84, 110), crop_shape=None):\n",
    "    assert(type(obs) == np.ndarray), \"The observation must be a numpy array!\"\n",
    "    assert(len(obs.shape) == 3), \"The observation must be a 3D array!\"\n",
    "\n",
    "    obs = cv2.resize(obs, resize_shape, interpolation=cv2.INTER_LINEAR)\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "    obs = obs / 255.\n",
    "    if crop_shape:\n",
    "        crop_x_margin = (resize_shape[1] - crop_shape[1]) // 2\n",
    "        crop_y_margin = (resize_shape[0] - crop_shape[0]) // 2\n",
    "        \n",
    "        x_start, x_end = crop_x_margin, resize_shape[1] - crop_x_margin\n",
    "        y_start, y_end = crop_y_margin, resize_shape[0] - crop_y_margin\n",
    "        \n",
    "        obs = obs[x_start:x_end, y_start:y_end]\n",
    "    \n",
    "    return obs\n",
    "\n",
    "def get_stacked_obs(obs, prev_frames):\n",
    "    if not prev_frames:\n",
    "        prev_frames = [obs] * (N_FRAMES - 1)\n",
    "        \n",
    "    prev_frames.append(obs)\n",
    "    stacked_frames = np.stack(prev_frames)\n",
    "    prev_frames = prev_frames[-(N_FRAMES-1):]\n",
    "    \n",
    "    return stacked_frames, prev_frames\n",
    "\n",
    "def preprocess_obs(obs, prev_frames):\n",
    "    filtered_obs = filter_obs(obs)\n",
    "    stacked_obs, prev_frames = get_stacked_obs(filtered_obs, prev_frames)\n",
    "    return stacked_obs, prev_frames\n",
    "\n",
    "def format_reward(reward):\n",
    "    if reward > 0:\n",
    "        return 1\n",
    "    elif reward < 0:\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Paper\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_acts):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(N_FRAMES, 32, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(32, 64, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Conv2d(64, 64, kernel_size=3, stride=1, padding=0),\n",
    "            nn.ReLU())\n",
    "\n",
    "        self.value_layer1 = nn.Sequential(\n",
    "            nn.Linear(64 * 10 * 7, 512),\n",
    "            nn.ReLU())\n",
    "        self.value_layer2 = nn.Linear(512, 1)\n",
    "\n",
    "        self.advantages_layer1 = nn.Sequential(\n",
    "            nn.Linear(64 * 10 * 7, 512),\n",
    "            nn.ReLU())\n",
    "        self.advantages_layer2 = nn.Linear(512, n_acts)\n",
    "        \n",
    "    def forward(self, obs):\n",
    "        z = self.layer1(obs)\n",
    "        z = self.layer2(z)\n",
    "        z = self.layer3(z)\n",
    "        z = z.view(-1, 64 * 10 * 7)\n",
    "        \n",
    "        values = self.value_layer1(z)\n",
    "        values = self.value_layer2(values)\n",
    "        \n",
    "        advantages = self.advantages_layer1(z)\n",
    "        advantages = self.advantages_layer2(advantages)\n",
    "        \n",
    "        advantage_means = torch.mean(advantages, dim=1)\n",
    "        advantages = advantages - advantage_means.view(-1, 1)\n",
    "        \n",
    "        qs = values + advantages\n",
    "        \n",
    "        return qs\n",
    "\n",
    "    def train_on_batch(self, target_model, optimizer, obs, acts, rewards, next_obs, terminals, gamma=0.99):\n",
    "        next_q_values = self.forward(next_obs)\n",
    "        max_next_acts = torch.max(next_q_values, dim=1)[1].detach()\n",
    "        \n",
    "        target_next_q_values = target_model.forward(next_obs)\n",
    "        max_next_q_values = target_next_q_values.gather(index=max_next_acts.view(-1, 1), dim=1)\n",
    "        max_next_q_values = max_next_q_values.view(-1).detach()\n",
    "        \n",
    "        terminal_mods = 1 - terminals\n",
    "        actual_qs = rewards + terminal_mods * gamma * max_next_q_values\n",
    "            \n",
    "        pred_qs = self.forward(obs)\n",
    "        pred_qs = pred_qs.gather(index=acts.view(-1, 1), dim=1).view(-1)\n",
    "        \n",
    "        loss = torch.mean((actual_qs - pred_qs) ** 2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.data = []\n",
    "        \n",
    "    def add_step(self, step_data):\n",
    "        self.data.append(step_data)\n",
    "        if len(self.data) > self.capacity:\n",
    "            self.data = self.data[-self.capacity:]\n",
    "            \n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.data))\n",
    "        indices = np.random.choice(range(len(self.data)), n, replace=False)\n",
    "        samples = np.asarray(self.data)[indices]\n",
    "        \n",
    "        state_data = torch.tensor(np.stack(samples[:, 0])).float().cuda()\n",
    "        act_data = torch.tensor(np.stack(samples[:, 1])).long().cuda()\n",
    "        reward_data = torch.tensor(np.stack(samples[:, 2])).float().cuda()\n",
    "        next_state_data = torch.tensor(np.stack(samples[:, 3])).float().cuda()\n",
    "        terminal_data = torch.tensor(np.stack(samples[:, 4])).float().cuda()\n",
    "        \n",
    "        return state_data, act_data, reward_data, next_state_data, terminal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Algorithm\n",
    "\n",
    "<img src='imgs/dqn_algorithm.png' width=80% align='left' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 100000\n",
    "max_steps = 1000\n",
    "er_capacity = 100000 # 1m in paper\n",
    "n_acts = env.action_space.n\n",
    "train_batch_size = 32\n",
    "learning_rate = 2.5e-4\n",
    "update_freq = 4\n",
    "print_freq = 100\n",
    "frame_skip = 3\n",
    "n_anneal_steps = 1e5 # Anneal over 1m steps in paper\n",
    "target_update_delay = 10000 # How many episodes in between target model update\n",
    "epsilon = lambda step: np.clip(1 - 0.9 * (step/n_anneal_steps), 0.1, 1) # Anneal over 1m steps in paper, 100k here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #0 | Step #81 | Epsilon 1.00 | Avg. Reward 1.00\n",
      "Episode #100 | Step #7406 | Epsilon 0.93 | Avg. Reward 1.55\n",
      "Episode #200 | Step #14753 | Epsilon 0.87 | Avg. Reward 1.48\n",
      "Episode #300 | Step #21996 | Epsilon 0.80 | Avg. Reward 1.37\n",
      "Episode #400 | Step #29560 | Epsilon 0.73 | Avg. Reward 1.22\n",
      "Episode #500 | Step #37326 | Epsilon 0.66 | Avg. Reward 1.68\n",
      "Episode #600 | Step #45757 | Epsilon 0.59 | Avg. Reward 1.90\n",
      "Episode #700 | Step #54542 | Epsilon 0.51 | Avg. Reward 1.68\n",
      "Episode #800 | Step #63782 | Epsilon 0.43 | Avg. Reward 1.21\n",
      "Episode #900 | Step #76240 | Epsilon 0.31 | Avg. Reward 3.75\n",
      "Episode #1000 | Step #94009 | Epsilon 0.15 | Avg. Reward 7.88\n",
      "Episode #1100 | Step #109151 | Epsilon 0.10 | Avg. Reward 8.06\n",
      "Episode #1200 | Step #124767 | Epsilon 0.10 | Avg. Reward 11.44\n",
      "Episode #1300 | Step #146621 | Epsilon 0.10 | Avg. Reward 14.75\n",
      "Episode #1400 | Step #167508 | Epsilon 0.10 | Avg. Reward 13.54\n",
      "Episode #1500 | Step #191454 | Epsilon 0.10 | Avg. Reward 15.97\n",
      "Episode #1600 | Step #213995 | Epsilon 0.10 | Avg. Reward 17.23\n",
      "Episode #1700 | Step #235499 | Epsilon 0.10 | Avg. Reward 19.28\n",
      "Episode #1800 | Step #259570 | Epsilon 0.10 | Avg. Reward 19.42\n",
      "Episode #1900 | Step #285575 | Epsilon 0.10 | Avg. Reward 20.56\n",
      "Episode #2000 | Step #310013 | Epsilon 0.10 | Avg. Reward 22.88\n",
      "Episode #2100 | Step #337609 | Epsilon 0.10 | Avg. Reward 24.60\n",
      "Episode #2200 | Step #364843 | Epsilon 0.10 | Avg. Reward 25.96\n",
      "Episode #2300 | Step #391813 | Epsilon 0.10 | Avg. Reward 26.25\n",
      "Episode #2400 | Step #421040 | Epsilon 0.10 | Avg. Reward 28.63\n",
      "Episode #2500 | Step #447648 | Epsilon 0.10 | Avg. Reward 28.94\n",
      "Episode #2600 | Step #475303 | Epsilon 0.10 | Avg. Reward 29.41\n",
      "Episode #2700 | Step #503157 | Epsilon 0.10 | Avg. Reward 29.00\n",
      "Episode #2800 | Step #531271 | Epsilon 0.10 | Avg. Reward 29.42\n",
      "Episode #2900 | Step #557558 | Epsilon 0.10 | Avg. Reward 26.96\n",
      "Episode #3000 | Step #585195 | Epsilon 0.10 | Avg. Reward 30.71\n",
      "Episode #3100 | Step #611137 | Epsilon 0.10 | Avg. Reward 26.46\n",
      "Episode #3200 | Step #637541 | Epsilon 0.10 | Avg. Reward 29.28\n",
      "Episode #3300 | Step #664472 | Epsilon 0.10 | Avg. Reward 29.28\n",
      "Episode #3400 | Step #690702 | Epsilon 0.10 | Avg. Reward 26.90\n",
      "Episode #3500 | Step #716468 | Epsilon 0.10 | Avg. Reward 29.36\n",
      "Episode #3600 | Step #743616 | Epsilon 0.10 | Avg. Reward 29.08\n",
      "Episode #3700 | Step #770845 | Epsilon 0.10 | Avg. Reward 29.27\n",
      "Episode #3800 | Step #798325 | Epsilon 0.10 | Avg. Reward 32.10\n",
      "Episode #3900 | Step #824511 | Epsilon 0.10 | Avg. Reward 30.20\n",
      "Episode #4000 | Step #849247 | Epsilon 0.10 | Avg. Reward 30.19\n",
      "Episode #4100 | Step #874513 | Epsilon 0.10 | Avg. Reward 30.37\n",
      "Episode #4200 | Step #900824 | Epsilon 0.10 | Avg. Reward 31.52\n",
      "Episode #4300 | Step #926917 | Epsilon 0.10 | Avg. Reward 30.60\n",
      "Episode #4400 | Step #952558 | Epsilon 0.10 | Avg. Reward 29.05\n",
      "Episode #4500 | Step #977981 | Epsilon 0.10 | Avg. Reward 28.39\n",
      "Episode #4600 | Step #1002761 | Epsilon 0.10 | Avg. Reward 32.50\n",
      "Episode #4700 | Step #1027398 | Epsilon 0.10 | Avg. Reward 27.78\n",
      "Episode #4800 | Step #1052274 | Epsilon 0.10 | Avg. Reward 28.31\n",
      "Episode #4900 | Step #1077599 | Epsilon 0.10 | Avg. Reward 30.90\n",
      "Episode #5000 | Step #1102895 | Epsilon 0.10 | Avg. Reward 33.04\n",
      "Episode #5100 | Step #1128003 | Epsilon 0.10 | Avg. Reward 31.92\n",
      "Episode #5200 | Step #1152724 | Epsilon 0.10 | Avg. Reward 30.20\n",
      "Episode #5300 | Step #1177500 | Epsilon 0.10 | Avg. Reward 30.38\n",
      "Episode #5400 | Step #1203128 | Epsilon 0.10 | Avg. Reward 32.26\n",
      "Episode #5500 | Step #1228719 | Epsilon 0.10 | Avg. Reward 33.78\n",
      "Episode #5600 | Step #1253122 | Epsilon 0.10 | Avg. Reward 33.70\n",
      "Episode #5700 | Step #1277624 | Epsilon 0.10 | Avg. Reward 32.24\n",
      "Episode #5800 | Step #1302050 | Epsilon 0.10 | Avg. Reward 33.19\n",
      "Episode #5900 | Step #1326445 | Epsilon 0.10 | Avg. Reward 35.29\n",
      "Episode #6000 | Step #1350612 | Epsilon 0.10 | Avg. Reward 34.12\n",
      "Episode #6100 | Step #1374341 | Epsilon 0.10 | Avg. Reward 28.73\n",
      "Episode #6200 | Step #1399188 | Epsilon 0.10 | Avg. Reward 27.03\n",
      "Episode #6300 | Step #1423442 | Epsilon 0.10 | Avg. Reward 32.33\n",
      "Episode #6400 | Step #1447738 | Epsilon 0.10 | Avg. Reward 30.91\n",
      "Episode #6500 | Step #1473711 | Epsilon 0.10 | Avg. Reward 36.07\n",
      "Episode #6600 | Step #1498842 | Epsilon 0.10 | Avg. Reward 40.16\n",
      "Episode #6700 | Step #1523421 | Epsilon 0.10 | Avg. Reward 35.56\n",
      "Episode #6800 | Step #1548450 | Epsilon 0.10 | Avg. Reward 34.62\n",
      "Episode #6900 | Step #1573134 | Epsilon 0.10 | Avg. Reward 31.36\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f76241d48f5e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mobs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             model.train_on_batch(target_model, optimizer, obs_data, act_data,\n\u001b[1;32m     44\u001b[0m                                  reward_data, next_obs_data, terminal_data)\n",
      "\u001b[0;32m<ipython-input-5-dc1b9234e6f1>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "er = ExperienceReplay(er_capacity)\n",
    "model = DQN(n_acts=env.action_space.n).cuda()\n",
    "target_model = copy.deepcopy(model)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, eps=1e-6)\n",
    "all_rewards = []\n",
    "global_step = 0\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    prev_frames = []\n",
    "    obs, prev_frames = preprocess_obs(env.reset(), prev_frames)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "    while step < max_steps:\n",
    "\n",
    "        ### Enact a step ###\n",
    "        \n",
    "        if np.random.rand() < epsilon(global_step):\n",
    "            act = np.random.choice(range(n_acts))\n",
    "        else:\n",
    "            obs_tensor = torch.tensor([obs]).float().cuda()\n",
    "            q_values = model(obs_tensor)[0]\n",
    "            q_values = q_values.cpu().detach().numpy()\n",
    "            act = np.argmax(q_values)\n",
    "        \n",
    "        cumulative_reward = 0\n",
    "        for _ in range(frame_skip):\n",
    "            next_obs, reward, done, _ = env.step(act)\n",
    "            cumulative_reward += reward\n",
    "            if done or step >= max_steps:\n",
    "                break\n",
    "        episode_reward += cumulative_reward\n",
    "        reward = format_reward(cumulative_reward)\n",
    "\n",
    "        next_obs, prev_frames = preprocess_obs(next_obs, prev_frames)\n",
    "        er.add_step([obs, act, reward, next_obs, int(done)])\n",
    "        obs = next_obs\n",
    "        \n",
    "        ### Train on a minibatch ###\n",
    "        \n",
    "        if global_step % update_freq == 0:\n",
    "            obs_data, act_data, reward_data, next_obs_data, terminal_data = er.sample(train_batch_size)\n",
    "            model.train_on_batch(target_model, optimizer, obs_data, act_data,\n",
    "                                 reward_data, next_obs_data, terminal_data)\n",
    "        \n",
    "        ### Update target network ###\n",
    "        \n",
    "        if global_step and global_step % target_update_delay == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "        \n",
    "        ### Finish the step ###\n",
    "        \n",
    "        step += 1\n",
    "        global_step += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    all_rewards.append(episode_reward)\n",
    "    \n",
    "    if episode % print_freq == 0:\n",
    "        print('Episode #{} | Step #{} | Epsilon {:.2f} | Avg. Reward {:.2f}'.format(\n",
    "            episode, global_step, epsilon(global_step), np.mean(all_rewards[-print_freq:])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frames = []\n",
    "obs, prev_frames = preprocess_obs(env.reset(), prev_frames)\n",
    "\n",
    "for step in range(max_steps):\n",
    "    if np.random.rand() < 0.05:\n",
    "        act = np.random.choice(range(n_acts))\n",
    "    else:\n",
    "        obs_tensor = torch.tensor([obs]).float().cuda()\n",
    "        q_values = model(obs_tensor)[0]\n",
    "        q_values = q_values.cpu().detach().numpy()\n",
    "        act = np.argmax(q_values)\n",
    "\n",
    "    for _ in range(frame_skip):\n",
    "        next_obs, reward, done, _ = env.step(act)\n",
    "        if done or step >= max_steps:\n",
    "            break\n",
    "            \n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    obs, prev_frames = preprocess_obs(next_obs, prev_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb4406ea90>]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoothed_rewards = []\n",
    "smooth_window = 50\n",
    "for i in range(smooth_window, len(all_rewards)-smooth_window):\n",
    "    smoothed_rewards.append(np.mean(all_rewards[i-smooth_window:i+smooth_window]))\n",
    "    \n",
    "plt.plot(range(len(smoothed_rewards)), smoothed_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type DQN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'models/dddqn_breakout_r31.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
