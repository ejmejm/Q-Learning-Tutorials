{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import time\n",
    "from torch import nn\n",
    "import gym\n",
    "import cv2\n",
    "import copy\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Action space: Discrete(4)\n",
      "Observation space: Box(210, 160, 3)\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('BreakoutDeterministic-v4')\n",
    "print('Action space:', env.action_space)\n",
    "print('Observation space:', env.observation_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FRAMES = 4\n",
    "\n",
    "def filter_obs(obs, resize_shape=(84, 110), crop_shape=None):\n",
    "    assert(type(obs) == np.ndarray), \"The observation must be a numpy array!\"\n",
    "    assert(len(obs.shape) == 3), \"The observation must be a 3D array!\"\n",
    "\n",
    "    obs = cv2.resize(obs, resize_shape, interpolation=cv2.INTER_LINEAR)\n",
    "    obs = cv2.cvtColor(obs, cv2.COLOR_BGR2GRAY)\n",
    "    obs = obs / 255.\n",
    "    if crop_shape:\n",
    "        crop_x_margin = (resize_shape[1] - crop_shape[1]) // 2\n",
    "        crop_y_margin = (resize_shape[0] - crop_shape[0]) // 2\n",
    "        \n",
    "        x_start, x_end = crop_x_margin, resize_shape[1] - crop_x_margin\n",
    "        y_start, y_end = crop_y_margin, resize_shape[0] - crop_y_margin\n",
    "        \n",
    "        obs = obs[x_start:x_end, y_start:y_end]\n",
    "    \n",
    "    return obs\n",
    "\n",
    "def get_stacked_obs(obs, prev_frames):\n",
    "    if not prev_frames:\n",
    "        prev_frames = [obs] * (N_FRAMES - 1)\n",
    "        \n",
    "    prev_frames.append(obs)\n",
    "    stacked_frames = np.stack(prev_frames)\n",
    "    prev_frames = prev_frames[-(N_FRAMES-1):]\n",
    "    \n",
    "    return stacked_frames, prev_frames\n",
    "\n",
    "def preprocess_obs(obs, prev_frames):\n",
    "    filtered_obs = filter_obs(obs)\n",
    "    stacked_obs, prev_frames = get_stacked_obs(filtered_obs, prev_frames)\n",
    "    return stacked_obs, prev_frames\n",
    "\n",
    "def format_reward(reward):\n",
    "    if reward > 0:\n",
    "        return 1\n",
    "    elif reward < 0:\n",
    "        return -1\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original Paper\n",
    "class DQN(nn.Module):\n",
    "    def __init__(self, n_acts):\n",
    "        super(DQN, self).__init__()\n",
    "        \n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(N_FRAMES, 16, kernel_size=8, stride=4, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer2 = nn.Sequential(\n",
    "            nn.Conv2d(16, 32, kernel_size=4, stride=2, padding=0),\n",
    "            nn.ReLU())\n",
    "        self.layer3 = nn.Sequential(\n",
    "            nn.Linear(32 * 12 * 9, 256),\n",
    "            nn.ReLU())\n",
    "        self.layer4 = nn.Sequential(\n",
    "            nn.Linear(256, n_acts))\n",
    "        \n",
    "    def forward(self, obs):\n",
    "        q_values = self.layer1(obs)\n",
    "        q_values = self.layer2(q_values)\n",
    "        \n",
    "        # 2015 model: (32, 8x8, 4), (64, 4x4, 2), (64, 3x3, 1), (512)\n",
    "        q_values = q_values.view(-1, 32 * 12 * 9)\n",
    "        q_values = self.layer3(q_values)\n",
    "        q_values = self.layer4(q_values)\n",
    "        \n",
    "        return q_values\n",
    "    \n",
    "    def train_on_batch(self, target_model, optimizer, obs, acts, rewards, next_obs, terminals, gamma=0.99):\n",
    "        next_q_values = target_model.forward(next_obs)\n",
    "        max_next_q_values = torch.max(next_q_values, dim=1)[0].detach()\n",
    "        \n",
    "        terminal_mods = 1 - terminals\n",
    "        actual_qs = rewards + terminal_mods * gamma * max_next_q_values\n",
    "            \n",
    "        pred_qs = self.forward(obs)\n",
    "        pred_qs = pred_qs.gather(index=acts.view(-1, 1), dim=1).view(-1)\n",
    "        \n",
    "        loss = torch.mean((actual_qs - pred_qs) ** 2)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperienceReplay():\n",
    "    def __init__(self, capacity):\n",
    "        self.capacity = capacity\n",
    "        self.data = []\n",
    "        \n",
    "    def add_step(self, step_data):\n",
    "        self.data.append(step_data)\n",
    "        if len(self.data) > self.capacity:\n",
    "            self.data = self.data[-self.capacity:]\n",
    "            \n",
    "    def sample(self, n):\n",
    "        n = min(n, len(self.data))\n",
    "        indices = np.random.choice(range(len(self.data)), n, replace=False)\n",
    "        samples = np.asarray(self.data)[indices]\n",
    "        \n",
    "        state_data = torch.tensor(np.stack(samples[:, 0])).float().cuda()\n",
    "        act_data = torch.tensor(np.stack(samples[:, 1])).long().cuda()\n",
    "        reward_data = torch.tensor(np.stack(samples[:, 2])).float().cuda()\n",
    "        next_state_data = torch.tensor(np.stack(samples[:, 3])).float().cuda()\n",
    "        terminal_data = torch.tensor(np.stack(samples[:, 4])).float().cuda()\n",
    "        \n",
    "        return state_data, act_data, reward_data, next_state_data, terminal_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DQN Algorithm\n",
    "\n",
    "<img src='imgs/dqn_algorithm.png' width=80% align='left' />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_episodes = 10000\n",
    "max_steps = 5000\n",
    "er_capacity = 150000 # 1m in paper\n",
    "n_acts = env.action_space.n # 0: no-op, 1: start game, 2: right, 3: left\n",
    "train_batch_size = 32\n",
    "learning_rate = 2.5e-4\n",
    "print_freq = 100\n",
    "update_freq = 4\n",
    "frame_skip = 3\n",
    "n_anneal_steps = 1e5 # Anneal over 1m steps in paper\n",
    "target_update_delay = 10000 # How many timesteps in between target model update\n",
    "epsilon = lambda step: np.clip(1 - 0.9 * (step/n_anneal_steps), 0.1, 1) # Anneal over 1m steps in paper, 100k here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode #0 | Step #94 | Epsilon 1.00 | Avg. Reward 3.00\n",
      "Episode #100 | Step #7247 | Epsilon 0.93 | Avg. Reward 1.44\n",
      "Episode #200 | Step #14293 | Epsilon 0.87 | Avg. Reward 1.16\n",
      "Episode #300 | Step #21821 | Epsilon 0.80 | Avg. Reward 1.44\n",
      "Episode #400 | Step #29218 | Epsilon 0.74 | Avg. Reward 1.22\n",
      "Episode #500 | Step #36796 | Epsilon 0.67 | Avg. Reward 1.30\n",
      "Episode #600 | Step #44008 | Epsilon 0.60 | Avg. Reward 0.78\n",
      "Episode #700 | Step #51350 | Epsilon 0.54 | Avg. Reward 0.89\n",
      "Episode #800 | Step #60693 | Epsilon 0.45 | Avg. Reward 2.09\n",
      "Episode #900 | Step #71689 | Epsilon 0.35 | Avg. Reward 3.18\n",
      "Episode #1000 | Step #86265 | Epsilon 0.22 | Avg. Reward 5.46\n",
      "Episode #1100 | Step #104289 | Epsilon 0.10 | Avg. Reward 8.54\n",
      "Episode #1200 | Step #119634 | Epsilon 0.10 | Avg. Reward 10.32\n",
      "Episode #1300 | Step #150842 | Epsilon 0.10 | Avg. Reward 17.47\n",
      "Episode #1400 | Step #179146 | Epsilon 0.10 | Avg. Reward 15.51\n",
      "Episode #1500 | Step #197695 | Epsilon 0.10 | Avg. Reward 16.74\n",
      "Episode #1600 | Step #220361 | Epsilon 0.10 | Avg. Reward 20.51\n",
      "Episode #1700 | Step #241209 | Epsilon 0.10 | Avg. Reward 20.79\n",
      "Episode #1800 | Step #264187 | Epsilon 0.10 | Avg. Reward 23.31\n",
      "Episode #1900 | Step #302409 | Epsilon 0.10 | Avg. Reward 25.47\n",
      "Episode #2000 | Step #328433 | Epsilon 0.10 | Avg. Reward 23.10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-63e015da1d31>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mglobal_step\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mupdate_freq\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m             \u001b[0mobs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mact_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_obs_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mterminal_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_batch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m             model.train_on_batch(target_model, optimizer, obs_data, act_data,\n\u001b[1;32m     44\u001b[0m                                  reward_data, next_obs_data, terminal_data)\n",
      "\u001b[0;32m<ipython-input-5-dc1b9234e6f1>\u001b[0m in \u001b[0;36msample\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mstate_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "er = ExperienceReplay(er_capacity)\n",
    "model = DQN(n_acts=env.action_space.n).cuda()\n",
    "target_model = copy.deepcopy(model)\n",
    "optimizer = torch.optim.RMSprop(model.parameters(), lr=learning_rate, eps=1e-6)\n",
    "all_rewards = []\n",
    "global_step = 0\n",
    "\n",
    "for episode in range(n_episodes):\n",
    "    prev_frames = []\n",
    "    obs, prev_frames = preprocess_obs(env.reset(), prev_frames)\n",
    "    \n",
    "    episode_reward = 0\n",
    "    step = 0\n",
    "    while step < max_steps:\n",
    "\n",
    "        ### Enact a step ###\n",
    "        \n",
    "        if np.random.rand() < epsilon(global_step):\n",
    "            act = np.random.choice(range(n_acts))\n",
    "        else:\n",
    "            obs_tensor = torch.tensor([obs]).float().cuda()\n",
    "            q_values = model(obs_tensor)[0]\n",
    "            q_values = q_values.cpu().detach().numpy()\n",
    "            act = np.argmax(q_values)\n",
    "        \n",
    "        cumulative_reward = 0\n",
    "        for _ in range(frame_skip):\n",
    "            next_obs, reward, done, _ = env.step(act)\n",
    "            cumulative_reward += reward\n",
    "            if done or step >= max_steps:\n",
    "                break\n",
    "        episode_reward += cumulative_reward\n",
    "        reward = format_reward(cumulative_reward)\n",
    "\n",
    "        next_obs, prev_frames = preprocess_obs(next_obs, prev_frames)\n",
    "        er.add_step([obs, act, reward, next_obs, int(done)])\n",
    "        obs = next_obs\n",
    "        \n",
    "        ### Train on a minibatch ###\n",
    "\n",
    "        if global_step % update_freq == 0:\n",
    "            obs_data, act_data, reward_data, next_obs_data, terminal_data = er.sample(train_batch_size)\n",
    "            model.train_on_batch(target_model, optimizer, obs_data, act_data,\n",
    "                                 reward_data, next_obs_data, terminal_data)\n",
    "        \n",
    "        ### Update target network ###\n",
    "        \n",
    "        if global_step and global_step % target_update_delay == 0:\n",
    "            target_model = copy.deepcopy(model)\n",
    "        \n",
    "        ### Finish the step ###\n",
    "        \n",
    "        step += 1\n",
    "        global_step += 1\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "            \n",
    "    all_rewards.append(episode_reward)\n",
    "    \n",
    "    if episode % print_freq == 0:\n",
    "        print('Episode #{} | Step #{} | Epsilon {:.2f} | Avg. Reward {:.2f}'.format(\n",
    "            episode, global_step, epsilon(global_step), np.mean(all_rewards[-print_freq:])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Render Example Episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_frames = []\n",
    "obs, prev_frames = preprocess_obs(env.reset(), prev_frames)\n",
    "\n",
    "for step in range(max_steps):\n",
    "    if np.random.rand() < 0.05:\n",
    "        act = np.random.choice(range(n_acts))\n",
    "    else:\n",
    "        obs_tensor = torch.tensor([obs]).float().cuda()\n",
    "        q_values = model(obs_tensor)[0]\n",
    "        q_values = q_values.cpu().detach().numpy()\n",
    "        act = np.argmax(q_values)\n",
    "\n",
    "    for _ in range(frame_skip):\n",
    "        next_obs, reward, done, _ = env.step(act)\n",
    "        if done or step >= max_steps:\n",
    "            break\n",
    "            \n",
    "        env.render()\n",
    "        time.sleep(0.05)\n",
    "        \n",
    "    if done:\n",
    "        break\n",
    "\n",
    "    obs, prev_frames = preprocess_obs(next_obs, prev_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7efb4b6db210>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "smoothed_rewards = []\n",
    "smooth_window = 50\n",
    "for i in range(smooth_window, len(all_rewards)-smooth_window):\n",
    "    smoothed_rewards.append(np.mean(all_rewards[i-smooth_window:i+smooth_window]))\n",
    "    \n",
    "plt.plot(range(len(smoothed_rewards)), smoothed_rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ejmejm/anaconda3/lib/python3.7/site-packages/torch/serialization.py:250: UserWarning: Couldn't retrieve source code for container of type DQN. It won't be checked for correctness upon loading.\n",
      "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
     ]
    }
   ],
   "source": [
    "torch.save(model, 'models/dqn_target_breakout_r23.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
